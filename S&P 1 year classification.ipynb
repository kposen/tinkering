{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Modules\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout, GaussianNoise, GRU, LSTM, Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Source data\n",
    "data_file_path = ''\n",
    "data_filename = 'spx_history.csv'\n",
    "\n",
    "# Model\n",
    "model_file = 'model.hd5'\n",
    "num_epochs = 10000\n",
    "validation_frac = 0.2\n",
    "batch_size = 128\n",
    "optimizer = 'adam'\n",
    "loss = 'binary_crossentropy'\n",
    "metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_samples(time_series, outcomes, duration, stride):\n",
    "    x, y = zip(*[(time_series[i-duration:i], outcomes[i]) for i in range(duration, len(time_series), stride)])\n",
    "    \n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_filename = os.path.join(data_file_path, data_filename)\n",
    "raw_data = pd.read_csv(full_filename, delimiter=',', parse_dates=[1], dayfirst=True)\n",
    "returns = raw_data.iloc[:,1].values\n",
    "decisions = raw_data.iloc[:,2].values\n",
    "\n",
    "x, y = get_samples(returns, decisions, 2500, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.expand_dims(x, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.expand_dims(y, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19751, 2500, 1)\n",
      "(19751, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    dropout = 0.5\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    # Convolutions\n",
    "    model.add(Conv1D(32, 2, padding='same', activation='relu', input_shape=(None,1)))\n",
    "    model.add(MaxPooling1D(2, padding='same'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Conv1D(64, 2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(2, padding='same'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Conv1D(128, 2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(2, padding='same'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Conv1D(128, 2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(2, padding='same'))\n",
    "    model.add(Dropout(dropout))\n",
    "#     model.add(Conv1D(128, 2, padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling1D(2, padding='same'))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     model.add(Conv1D(128, 2, padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling1D(2, padding='same'))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     model.add(Conv1D(128, 2, padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling1D(2, padding='same'))\n",
    "#     model.add(Dropout(dropout))\n",
    "    \n",
    "#     # Recurrents\n",
    "#     model.add(GRU(128, return_sequences=True, go_backwards=True))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     model.add(GRU(128, return_sequences=False, go_backwards=False))\n",
    "#     model.add(Dropout(dropout))\n",
    "    \n",
    "    # Dense for final prediction\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, None, 32)          96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, None, 64)          4160      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, None, 128)         16512     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, None, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, None, 64)          8256      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, None, 16)          528       \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, None, 8)           136       \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, None, 8)           0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, None, 4)           36        \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, None, 4)           0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, None, 2)           10        \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, None, 2)           0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, None, 1)           3         \n",
      "=================================================================\n",
      "Total params: 64,713\n",
      "Trainable params: 64,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15800 samples, validate on 3951 samples\n",
      "Epoch 1/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6936 - acc: 0.5106Epoch 00000: val_loss improved from inf to 0.69289, saving model to model.hd5\n",
      "15800/15800 [==============================] - 177s - loss: 0.6936 - acc: 0.5104 - val_loss: 0.6929 - val_acc: 0.5143\n",
      "Epoch 2/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6930 - acc: 0.5116Epoch 00001: val_loss improved from 0.69289 to 0.69282, saving model to model.hd5\n",
      "15800/15800 [==============================] - 171s - loss: 0.6930 - acc: 0.5114 - val_loss: 0.6928 - val_acc: 0.5143\n",
      "Epoch 3/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6929 - acc: 0.5114Epoch 00002: val_loss improved from 0.69282 to 0.69278, saving model to model.hd5\n",
      "15800/15800 [==============================] - 164s - loss: 0.6929 - acc: 0.5114 - val_loss: 0.6928 - val_acc: 0.5143\n",
      "Epoch 4/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6929 - acc: 0.5115Epoch 00003: val_loss improved from 0.69278 to 0.69277, saving model to model.hd5\n",
      "15800/15800 [==============================] - 162s - loss: 0.6929 - acc: 0.5116 - val_loss: 0.6928 - val_acc: 0.5143\n",
      "Epoch 5/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6929 - acc: 0.5120Epoch 00004: val_loss improved from 0.69277 to 0.69276, saving model to model.hd5\n",
      "15800/15800 [==============================] - 165s - loss: 0.6929 - acc: 0.5116 - val_loss: 0.6928 - val_acc: 0.5143\n",
      "Epoch 6/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6929 - acc: 0.5118Epoch 00005: val_loss did not improve\n",
      "15800/15800 [==============================] - 162s - loss: 0.6929 - acc: 0.5119 - val_loss: 0.6928 - val_acc: 0.5143\n",
      "Epoch 7/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6928 - acc: 0.5125Epoch 00006: val_loss improved from 0.69276 to 0.69275, saving model to model.hd5\n",
      "15800/15800 [==============================] - 162s - loss: 0.6929 - acc: 0.5123 - val_loss: 0.6928 - val_acc: 0.5143\n",
      "Epoch 8/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6928 - acc: 0.5127Epoch 00007: val_loss did not improve\n",
      "15800/15800 [==============================] - 164s - loss: 0.6928 - acc: 0.5128 - val_loss: 0.6928 - val_acc: 0.5143\n",
      "Epoch 9/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6928 - acc: 0.5130Epoch 00008: val_loss did not improve\n",
      "15800/15800 [==============================] - 161s - loss: 0.6928 - acc: 0.5133 - val_loss: 0.6928 - val_acc: 0.5143\n",
      "Epoch 10/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6927 - acc: 0.5144Epoch 00009: val_loss did not improve\n",
      "15800/15800 [==============================] - 163s - loss: 0.6927 - acc: 0.5143 - val_loss: 0.6928 - val_acc: 0.5143\n",
      "Epoch 11/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6927 - acc: 0.5123Epoch 00010: val_loss improved from 0.69275 to 0.69275, saving model to model.hd5\n",
      "15800/15800 [==============================] - 164s - loss: 0.6927 - acc: 0.5126 - val_loss: 0.6927 - val_acc: 0.5143\n",
      "Epoch 12/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6927 - acc: 0.5139Epoch 00011: val_loss improved from 0.69275 to 0.69274, saving model to model.hd5\n",
      "15800/15800 [==============================] - 162s - loss: 0.6927 - acc: 0.5138 - val_loss: 0.6927 - val_acc: 0.5143\n",
      "Epoch 13/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6926 - acc: 0.5157Epoch 00012: val_loss did not improve\n",
      "15800/15800 [==============================] - 162s - loss: 0.6926 - acc: 0.5152 - val_loss: 0.6927 - val_acc: 0.5143\n",
      "Epoch 14/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6925 - acc: 0.5162Epoch 00013: val_loss did not improve\n",
      "15800/15800 [==============================] - 163s - loss: 0.6925 - acc: 0.5160 - val_loss: 0.6927 - val_acc: 0.5143\n",
      "Epoch 15/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6924 - acc: 0.5165Epoch 00014: val_loss did not improve\n",
      "15800/15800 [==============================] - 162s - loss: 0.6924 - acc: 0.5165 - val_loss: 0.6928 - val_acc: 0.5143\n",
      "Epoch 16/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6925 - acc: 0.5160Epoch 00015: val_loss did not improve\n",
      "15800/15800 [==============================] - 163s - loss: 0.6925 - acc: 0.5161 - val_loss: 0.6928 - val_acc: 0.5143\n",
      "Epoch 17/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6924 - acc: 0.5170Epoch 00016: val_loss did not improve\n",
      "15800/15800 [==============================] - 161s - loss: 0.6924 - acc: 0.5170 - val_loss: 0.6928 - val_acc: 0.5143\n",
      "Epoch 18/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6924 - acc: 0.5168Epoch 00017: val_loss did not improve\n",
      "15800/15800 [==============================] - 161s - loss: 0.6924 - acc: 0.5167 - val_loss: 0.6928 - val_acc: 0.5142\n",
      "Epoch 19/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6924 - acc: 0.5171Epoch 00018: val_loss did not improve\n",
      "15800/15800 [==============================] - 164s - loss: 0.6923 - acc: 0.5173 - val_loss: 0.6928 - val_acc: 0.5143\n",
      "Epoch 20/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6923 - acc: 0.5171Epoch 00019: val_loss did not improve\n",
      "15800/15800 [==============================] - 177s - loss: 0.6923 - acc: 0.5175 - val_loss: 0.6928 - val_acc: 0.5143\n",
      "Epoch 21/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6923 - acc: 0.5173Epoch 00020: val_loss did not improve\n",
      "15800/15800 [==============================] - 168s - loss: 0.6923 - acc: 0.5174 - val_loss: 0.6928 - val_acc: 0.5143\n",
      "Epoch 22/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6922 - acc: 0.5188Epoch 00021: val_loss did not improve\n",
      "15800/15800 [==============================] - 167s - loss: 0.6922 - acc: 0.5189 - val_loss: 0.6928 - val_acc: 0.5143\n",
      "Epoch 23/10000\n",
      "15744/15800 [============================>.] - ETA: 0s - loss: 0.6921 - acc: 0.5193Epoch 00022: val_loss did not improve\n",
      "15800/15800 [==============================] - 162s - loss: 0.6921 - acc: 0.5197 - val_loss: 0.6928 - val_acc: 0.5143\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=model_file, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "training_history = model.fit(x, y, batch_size=batch_size, epochs=num_epochs, verbose=1,\n",
    "          callbacks=[checkpointer, earlystopper], validation_split=validation_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
