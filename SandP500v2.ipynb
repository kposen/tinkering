{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Modules\n",
    "import datetime as dt\n",
    "import matplotlib as mp\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Dense, Dropout, GaussianNoise, GRU, LSTM, Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Source data\n",
    "data_file_path = ''\n",
    "data_filename = 'spx_history.csv'\n",
    "\n",
    "# Model\n",
    "model_file = 'model.hd5'\n",
    "num_epochs = 10000\n",
    "validation_frac = 0.2\n",
    "batch_size = 128\n",
    "optimizer = 'adam'\n",
    "loss = 'binary_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# Other config\n",
    "dt_format = '%Y-%m-%d'\n",
    "window = 2500 # days\n",
    "investment_horizon = 250 # days\n",
    "stride = 1 #days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_price_data(filename, dt_format):\n",
    "    prices = pd.read_csv(filename,\n",
    "                         delimiter=',',\n",
    "                         header=0,\n",
    "                         names=['date', 'P_close'],\n",
    "                         index_col=0,\n",
    "                         parse_dates=True,\n",
    "                         date_parser=lambda date_str: dt.datetime.strptime(date_str, dt_format))\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_processed_data(prices_df, investment_horizon):\n",
    "    prices_df['log_P'] = prices_df['P_close'].apply(np.log)\n",
    "    prices_df['diff'] = prices_df['log_P'].diff(1)\n",
    "    midpoint = (prices_df['diff'].max() + prices_df['diff'].min())/2\n",
    "    scale = (prices_df['diff'].max() - prices_df['diff'].min())/2\n",
    "    prices_df['scaled'] = (prices_df['diff'] - midpoint)/scale\n",
    "\n",
    "    def map_outcome(x):\n",
    "        if x == False:\n",
    "            return 0\n",
    "        elif x == True:\n",
    "            return 1\n",
    "        else:\n",
    "            return np.nan\n",
    "    \n",
    "    prices_df['return'] = prices_df['log_P'].diff(investment_horizon)\n",
    "    prices_df['outcome'] = (prices_df['return'] > prices_df['diff'].median()).map(map_outcome)\n",
    "    \n",
    "    print(prices_df.head())\n",
    "    print(prices_df.describe())\n",
    "\n",
    "    return prices_df[['scaled', 'outcome']].dropna(), midpoint, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_samples(data_df, window, stride):\n",
    "    time_series = data_df.iloc[:, 0].values\n",
    "    outcomes = data_df.iloc[:, 1].values\n",
    "    x, y = zip(*[(time_series[i-window:i], outcomes[i]) for i in range(window, len(time_series), stride)])\n",
    "    \n",
    "    return np.array(x).reshape(-1, window, 1), np.array(y).reshape(-1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    dropout = 0.5\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    # Convolutions\n",
    "    model.add(Conv1D(32, 2, padding='same', activation='relu', input_shape=(None,1)))\n",
    "    model.add(MaxPooling1D(2, padding='same'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Conv1D(64, 2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(2, padding='same'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Conv1D(128, 2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(2, padding='same'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Conv1D(128, 2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(2, padding='same'))\n",
    "    model.add(Dropout(dropout))\n",
    "#     model.add(Conv1D(128, 2, padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling1D(2, padding='same'))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     model.add(Conv1D(128, 2, padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling1D(2, padding='same'))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     model.add(Conv1D(128, 2, padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling1D(2, padding='same'))\n",
    "#     model.add(Dropout(dropout))\n",
    "    \n",
    "#     # Recurrents\n",
    "#     model.add(GRU(128, return_sequences=True, go_backwards=True))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     model.add(GRU(128, return_sequences=False, go_backwards=False))\n",
    "#     model.add(Dropout(dropout))\n",
    "    \n",
    "    # Dense for final prediction\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            P_close     log_P      diff    scaled  return  outcome\n",
      "date                                                              \n",
      "1927-12-30    17.66  2.871302       NaN       NaN     NaN        0\n",
      "1928-01-03    17.76  2.876949  0.005647  0.226387     NaN        0\n",
      "1928-01-04    17.72  2.874694 -0.002255  0.185090     NaN        0\n",
      "1928-01-05    17.55  2.865054 -0.009640  0.146491     NaN        0\n",
      "1928-01-06    17.66  2.871302  0.006248  0.229532     NaN        0\n",
      "            P_close         log_P          diff        scaled        return  \\\n",
      "count  22504.000000  22504.000000  22503.000000  22503.000000  22254.000000   \n",
      "mean     399.850251      4.734416      0.000220      0.198023      0.053370   \n",
      "std      573.245719      1.723863      0.011763      0.061478      0.203029   \n",
      "min        4.400000      1.481605     -0.228997     -1.000000     -1.223378   \n",
      "25%       22.987500      3.134951     -0.004572      0.172979     -0.044455   \n",
      "50%       96.700000      4.571613      0.000460      0.199277      0.083738   \n",
      "75%      503.140000      6.220868      0.005369      0.224938      0.181344   \n",
      "max     2477.830000      7.815138      0.153661      1.000000      1.008532   \n",
      "\n",
      "            outcome  \n",
      "count  22504.000000  \n",
      "mean       0.673658  \n",
      "std        0.468884  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        1.000000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n"
     ]
    }
   ],
   "source": [
    "full_filename = os.path.join(data_file_path, data_filename)\n",
    "data = get_price_data(full_filename, dt_format)\n",
    "processed_data, midpoint, scale = get_processed_data(data, investment_horizon)\n",
    "X, y = get_samples(processed_data, window, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20003, 2500, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, None, 32)          96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 64)          4160      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 128)         16512     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 64)          8256      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, None, 16)          528       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, None, 8)           136       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, None, 8)           0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, None, 4)           36        \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, None, 4)           0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, None, 2)           10        \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, None, 2)           0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, None, 1)           3         \n",
      "=================================================================\n",
      "Total params: 64,713\n",
      "Trainable params: 64,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16002 samples, validate on 4001 samples\n",
      "Epoch 1/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6820 - acc: 0.6939Epoch 00000: val_loss improved from inf to 0.66727, saving model to model.hd5\n",
      "16002/16002 [==============================] - 19s - loss: 0.6820 - acc: 0.6938 - val_loss: 0.6673 - val_acc: 0.7318\n",
      "Epoch 2/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6635 - acc: 0.6965Epoch 00001: val_loss improved from 0.66727 to 0.64763, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6635 - acc: 0.6965 - val_loss: 0.6476 - val_acc: 0.7318\n",
      "Epoch 3/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6489 - acc: 0.6965Epoch 00002: val_loss improved from 0.64763 to 0.63151, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6489 - acc: 0.6965 - val_loss: 0.6315 - val_acc: 0.7318\n",
      "Epoch 4/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6379 - acc: 0.6966Epoch 00003: val_loss improved from 0.63151 to 0.61919, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6379 - acc: 0.6965 - val_loss: 0.6192 - val_acc: 0.7318\n",
      "Epoch 5/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6304 - acc: 0.6966Epoch 00004: val_loss improved from 0.61919 to 0.61034, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6304 - acc: 0.6965 - val_loss: 0.6103 - val_acc: 0.7318\n",
      "Epoch 6/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6249 - acc: 0.6966Epoch 00005: val_loss improved from 0.61034 to 0.60341, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6249 - acc: 0.6965 - val_loss: 0.6034 - val_acc: 0.7318\n",
      "Epoch 7/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6209 - acc: 0.6966Epoch 00006: val_loss improved from 0.60341 to 0.59815, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6210 - acc: 0.6965 - val_loss: 0.5982 - val_acc: 0.7318\n",
      "Epoch 8/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6183 - acc: 0.6966Epoch 00007: val_loss improved from 0.59815 to 0.59428, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6183 - acc: 0.6965 - val_loss: 0.5943 - val_acc: 0.7318\n",
      "Epoch 9/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6166 - acc: 0.6965Epoch 00008: val_loss improved from 0.59428 to 0.59152, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6166 - acc: 0.6965 - val_loss: 0.5915 - val_acc: 0.7318\n",
      "Epoch 10/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6153 - acc: 0.6966Epoch 00009: val_loss improved from 0.59152 to 0.58935, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6153 - acc: 0.6965 - val_loss: 0.5893 - val_acc: 0.7318\n",
      "Epoch 11/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6147 - acc: 0.6965Epoch 00010: val_loss improved from 0.58935 to 0.58792, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6147 - acc: 0.6965 - val_loss: 0.5879 - val_acc: 0.7318\n",
      "Epoch 12/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6143 - acc: 0.6965Epoch 00011: val_loss improved from 0.58792 to 0.58673, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6142 - acc: 0.6965 - val_loss: 0.5867 - val_acc: 0.7318\n",
      "Epoch 13/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6140 - acc: 0.6966Epoch 00012: val_loss improved from 0.58673 to 0.58594, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6140 - acc: 0.6965 - val_loss: 0.5859 - val_acc: 0.7318\n",
      "Epoch 14/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6139 - acc: 0.6966Epoch 00013: val_loss improved from 0.58594 to 0.58554, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6139 - acc: 0.6965 - val_loss: 0.5855 - val_acc: 0.7318\n",
      "Epoch 15/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6139 - acc: 0.6965Epoch 00014: val_loss improved from 0.58554 to 0.58525, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6139 - acc: 0.6965 - val_loss: 0.5852 - val_acc: 0.7318\n",
      "Epoch 16/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6966Epoch 00015: val_loss improved from 0.58525 to 0.58492, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5849 - val_acc: 0.7318\n",
      "Epoch 17/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6965Epoch 00016: val_loss improved from 0.58492 to 0.58480, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5848 - val_acc: 0.7318\n",
      "Epoch 18/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6965Epoch 00017: val_loss improved from 0.58480 to 0.58450, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5845 - val_acc: 0.7318\n",
      "Epoch 19/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6966Epoch 00018: val_loss improved from 0.58450 to 0.58445, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5845 - val_acc: 0.7318\n",
      "Epoch 20/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6965Epoch 00019: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5845 - val_acc: 0.7318\n",
      "Epoch 21/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6966Epoch 00020: val_loss improved from 0.58445 to 0.58435, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5843 - val_acc: 0.7318\n",
      "Epoch 22/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6966Epoch 00021: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5844 - val_acc: 0.7318\n",
      "Epoch 23/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6966Epoch 00022: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5845 - val_acc: 0.7318\n",
      "Epoch 24/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6965Epoch 00023: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5846 - val_acc: 0.7318\n",
      "Epoch 25/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6966Epoch 00024: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5845 - val_acc: 0.7318\n",
      "Epoch 26/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6966Epoch 00025: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5845 - val_acc: 0.7318\n",
      "Epoch 27/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6965Epoch 00026: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5845 - val_acc: 0.7318\n",
      "Epoch 28/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6965Epoch 00027: val_loss improved from 0.58435 to 0.58434, saving model to model.hd5\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5843 - val_acc: 0.7318\n",
      "Epoch 29/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6966Epoch 00028: val_loss improved from 0.58434 to 0.58430, saving model to model.hd5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5843 - val_acc: 0.7318\n",
      "Epoch 30/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6966Epoch 00029: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5845 - val_acc: 0.7318\n",
      "Epoch 31/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6965Epoch 00030: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5846 - val_acc: 0.7318\n",
      "Epoch 32/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6966Epoch 00031: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5844 - val_acc: 0.7318\n",
      "Epoch 33/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6137 - acc: 0.6966Epoch 00032: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5846 - val_acc: 0.7318\n",
      "Epoch 34/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6966Epoch 00033: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5848 - val_acc: 0.7318\n",
      "Epoch 35/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6965Epoch 00034: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5848 - val_acc: 0.7318\n",
      "Epoch 36/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6966Epoch 00035: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5846 - val_acc: 0.7318\n",
      "Epoch 37/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6966Epoch 00036: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5846 - val_acc: 0.7318\n",
      "Epoch 38/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6966Epoch 00037: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5846 - val_acc: 0.7318\n",
      "Epoch 39/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6966Epoch 00038: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5847 - val_acc: 0.7318\n",
      "Epoch 40/10000\n",
      "16000/16002 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.6965Epoch 00039: val_loss did not improve\n",
      "16002/16002 [==============================] - 12s - loss: 0.6138 - acc: 0.6965 - val_loss: 0.5846 - val_acc: 0.7318\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=model_file, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "training_history = model.fit(X, y, batch_size=batch_size, epochs=num_epochs, verbose=1,\n",
    "          callbacks=[checkpointer, earlystopper], validation_split=validation_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
