{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Modules\n",
    "import datetime as dt\n",
    "import matplotlib as mp\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Dense, Dropout, GaussianNoise, GRU, LSTM, Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Source data\n",
    "data_file_path = ''\n",
    "data_filename = 'spx_history.csv'\n",
    "\n",
    "# Model\n",
    "model_file = 'model.hd5'\n",
    "num_epochs = 10000\n",
    "validation_frac = 0.2\n",
    "batch_size = 128\n",
    "optimizer = 'adam'\n",
    "loss = 'binary_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# Other config\n",
    "dt_format = '%Y-%m-%d'\n",
    "window = 2500 # days\n",
    "investment_horizon = 250 # days\n",
    "stride = 1 #days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_data(filename, dt_format):\n",
    "    prices = pd.read_csv(filename,\n",
    "                         delimiter=',',\n",
    "                         header=0,\n",
    "                         names=['date', 'P_close'],\n",
    "                         index_col=0,\n",
    "                         parse_dates=True,\n",
    "                         date_parser=lambda date_str: dt.datetime.strptime(date_str, dt_format))\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_data(prices_df, investment_horizon):\n",
    "    prices_df['log_P'] = prices_df['P_close'].apply(np.log)\n",
    "    prices_df['diff'] = prices_df['log_P'].diff(1)\n",
    "    midpoint = (prices_df['diff'].max() + prices_df['diff'].min())/2\n",
    "    scale = (prices_df['diff'].max() - prices_df['diff'].min())/2\n",
    "    prices_df['scaled'] = (prices_df['diff'] - midpoint)/scale\n",
    "\n",
    "    def map_outcome(x):\n",
    "        if x == False:\n",
    "            return 0\n",
    "        elif x == True:\n",
    "            return 1\n",
    "        else:\n",
    "            return np.nan\n",
    "    \n",
    "    prices_df['return'] = prices_df['log_P'].diff(investment_horizon)\n",
    "    prices_df['outcome'] = (prices_df['return'] > prices_df['diff'].median()).map(map_outcome)\n",
    "    \n",
    "    print(prices_df.head())\n",
    "    print(prices_df.describe())\n",
    "\n",
    "    return prices_df[['scaled', 'outcome']].dropna(), midpoint, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_samples(data_df, window, stride):\n",
    "    time_series = data_df.iloc[:, 0].values\n",
    "    outcomes = data_df.iloc[:, 1].values\n",
    "    x, y = zip(*[(time_series[i-window:i], outcomes[i]) for i in range(window, len(time_series), stride)])\n",
    "    \n",
    "    return np.array(x).reshape(-1, window, 1), np.array(y).reshape(-1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(range(20))\n",
    "x[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    dropout = 0.5\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    # Convolutions\n",
    "    model.add(Conv1D(32, 2, padding='same', activation='relu', input_shape=(None,1)))\n",
    "    model.add(MaxPooling1D(2, padding='same'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Conv1D(64, 2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(2, padding='same'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Conv1D(128, 2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(2, padding='same'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Conv1D(128, 2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(2, padding='same'))\n",
    "    model.add(Dropout(dropout))\n",
    "#     model.add(Conv1D(128, 2, padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling1D(2, padding='same'))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     model.add(Conv1D(128, 2, padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling1D(2, padding='same'))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     model.add(Conv1D(128, 2, padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling1D(2, padding='same'))\n",
    "#     model.add(Dropout(dropout))\n",
    "    \n",
    "#     # Recurrents\n",
    "#     model.add(GRU(128, return_sequences=True, go_backwards=True))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     model.add(GRU(128, return_sequences=False, go_backwards=False))\n",
    "#     model.add(Dropout(dropout))\n",
    "    \n",
    "    # Dense for final prediction\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            P_close     log_P      diff    scaled  return  outcome\n",
      "date                                                              \n",
      "1927-12-30    17.66  2.871302       NaN       NaN     NaN        0\n",
      "1928-01-03    17.76  2.876949  0.005647  0.226387     NaN        0\n",
      "1928-01-04    17.72  2.874694 -0.002255  0.185090     NaN        0\n",
      "1928-01-05    17.55  2.865054 -0.009640  0.146491     NaN        0\n",
      "1928-01-06    17.66  2.871302  0.006248  0.229532     NaN        0\n",
      "            P_close         log_P          diff        scaled        return  \\\n",
      "count  22504.000000  22504.000000  22503.000000  22503.000000  22254.000000   \n",
      "mean     399.850251      4.734416      0.000220      0.198023      0.053370   \n",
      "std      573.245719      1.723863      0.011763      0.061478      0.203029   \n",
      "min        4.400000      1.481605     -0.228997     -1.000000     -1.223378   \n",
      "25%       22.987500      3.134951     -0.004572      0.172979     -0.044455   \n",
      "50%       96.700000      4.571613      0.000460      0.199277      0.083738   \n",
      "75%      503.140000      6.220868      0.005369      0.224938      0.181344   \n",
      "max     2477.830000      7.815138      0.153661      1.000000      1.008532   \n",
      "\n",
      "            outcome  \n",
      "count  22504.000000  \n",
      "mean       0.673658  \n",
      "std        0.468884  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        1.000000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n"
     ]
    }
   ],
   "source": [
    "full_filename = os.path.join(data_file_path, data_filename)\n",
    "data = get_price_data(full_filename, dt_format)\n",
    "processed_data, midpoint, scale = get_processed_data(data, investment_horizon)\n",
    "X, y = get_samples(processed_data, window, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20003, 2500, 1)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, None, 32)          96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, None, 64)          4160      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, None, 128)         16512     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, None, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, None, 64)          8256      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, None, 16)          528       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, None, 8)           136       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, None, 8)           0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, None, 4)           36        \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, None, 4)           0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, None, 2)           10        \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, None, 2)           0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, None, 1)           3         \n",
      "=================================================================\n",
      "Total params: 64,713\n",
      "Trainable params: 64,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17802 samples, validate on 4451 samples\n",
      "Epoch 1/10000\n",
      " 3456/17802 [====>.........................] - ETA: 38s - loss: 0.6936 - acc: 0.4991"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-156-93a14db9aeaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m training_history = model.fit(X, y, batch_size=batch_size, epochs=num_epochs, verbose=1,\n\u001b[1;32m----> 5\u001b[1;33m           callbacks=[checkpointer, earlystopper], validation_split=validation_frac)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda3\\envs\\aind\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda3\\envs\\aind\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1430\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda3\\envs\\aind\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1080\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda3\\envs\\aind\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2268\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda3\\envs\\aind\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda3\\envs\\aind\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda3\\envs\\aind\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda3\\envs\\aind\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Miniconda3\\envs\\aind\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=model_file, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "training_history = model.fit(X, y, batch_size=batch_size, epochs=num_epochs, verbose=1,\n",
    "          callbacks=[checkpointer, earlystopper], validation_split=validation_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
